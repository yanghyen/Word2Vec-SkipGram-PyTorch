{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a7ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: í™˜ê²½ ì„¤ì •, ë¼ì´ë¸ŒëŸ¬ë¦¬, ë°ì´í„° ë¡œë“œ ë° í—¬í¼ í•¨ìˆ˜ ì •ì˜\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "from scipy.stats import spearmanr\n",
    "from tqdm.notebook import tqdm\n",
    "import argparse\n",
    "# from model import SkipGram  # ğŸš¨ ì‹¤ì œ SkipGram í´ë˜ìŠ¤ë¥¼ import í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "# ======================================================\n",
    "# 1. ê²½ë¡œ ì„¤ì • (í•„ìˆ˜ ìˆ˜ì •)\n",
    "# ======================================================\n",
    "\n",
    "# ğŸ› ï¸ ì´ ê²½ë¡œë“¤ì„ ì‹¤ì œ íŒŒì¼ ìœ„ì¹˜ì— ë§ê²Œ ìˆ˜ì •í•´ì£¼ì„¸ìš”!\n",
    "CONFIG_PATH = \"../configs/skipgram_example.yaml\"   \n",
    "VOCAB_PATH = \"../runs/vocab.pkl\"                 \n",
    "NS_CHECKPOINT_PATH = \"../weights/sgns_model.pt\"    # NS ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸\n",
    "HS_CHECKPOINT_PATH = \"../weights/sghs_model.pt\"    # HS ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸\n",
    "\n",
    "WORDSIM_CSV = \"../data/wordsim/WordSim353_combined.csv\"\n",
    "SIMLEX_TXT = \"../data/simlex/SimLex-999.txt\"\n",
    "GOOGLE_ANALOGY = \"../data/analogy/questions-words.txt\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ğŸ§  Using device: {device}\")\n",
    "\n",
    "# ======================================================\n",
    "# 2. Config & Vocabulary ë¡œë“œ\n",
    "# ======================================================\n",
    "\n",
    "with open(CONFIG_PATH, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "with open(VOCAB_PATH, \"rb\") as f:\n",
    "    vocab_data = pickle.load(f)\n",
    "vocab, word2idx, idx2word = vocab_data[\"vocab\"], vocab_data[\"word2idx\"], vocab_data[\"idx2word\"]\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = config[\"embedding_dim\"]\n",
    "print(f\"ğŸ“š Loaded vocab: {vocab_size} words. Dim: {embedding_dim}\")\n",
    "\n",
    "# ======================================================\n",
    "# 3. Data Loaders\n",
    "# ======================================================\n",
    "\n",
    "def load_wordsim353(path):\n",
    "    pairs = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            w1, w2, sim = row[0].lower(), row[1].lower(), float(row[2])\n",
    "            pairs.append((w1, w2, sim))\n",
    "    return pairs\n",
    "\n",
    "def load_simlex999(path):\n",
    "    pairs = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            w1, w2, sim = row['word1'].lower(), row['word2'].lower(), float(row['SimLex999'])\n",
    "            pairs.append((w1, w2, sim))\n",
    "    return pairs\n",
    "\n",
    "def load_google_analogy(path):\n",
    "    analogies = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\":\") or len(line) == 0:\n",
    "                continue\n",
    "            words = line.lower().split()\n",
    "            if len(words) == 4:\n",
    "                analogies.append(tuple(words))\n",
    "    return analogies\n",
    "\n",
    "ws_pairs = load_wordsim353(WORDSIM_CSV)\n",
    "simlex_pairs = load_simlex999(SIMLEX_TXT)\n",
    "analogy_pairs = load_google_analogy(GOOGLE_ANALOGY)\n",
    "print(\"âœ… Evaluation datasets loaded.\")\n",
    "\n",
    "# ======================================================\n",
    "# 4. Helper & Evaluation Functions\n",
    "# ======================================================\n",
    "\n",
    "# ğŸš¨ ì£¼ì˜: embedding_matrixëŠ” ê° ëª¨ë¸ í‰ê°€ ì…€ì—ì„œ ì „ì—­ ë³€ìˆ˜ë¡œ ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤!\n",
    "embedding_matrix = None \n",
    "\n",
    "def get_embedding(word):\n",
    "    global embedding_matrix\n",
    "    if word not in word2idx:\n",
    "        return None\n",
    "    return embedding_matrix[word2idx[word]]\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    return torch.dot(v1, v2) / (torch.norm(v1) * torch.norm(v2))\n",
    "\n",
    "@torch.no_grad()\n",
    "def analogy(a, b, c, topk=1):\n",
    "    global embedding_matrix\n",
    "    e_a, e_b, e_c = get_embedding(a), get_embedding(b), get_embedding(c)\n",
    "    if e_a is None or e_b is None or e_c is None:\n",
    "        return []\n",
    "        \n",
    "    target_vec = e_b - e_a + e_c\n",
    "    target_vec = target_vec.half() \n",
    "    \n",
    "    sims = torch.nn.functional.cosine_similarity(embedding_matrix, target_vec.unsqueeze(0), dim=1)\n",
    "\n",
    "    for w in [a, b, c]:\n",
    "        if w in word2idx:\n",
    "            sims[word2idx[w]] = -float(\"inf\")\n",
    "\n",
    "    topk_idx = torch.topk(sims, topk).indices\n",
    "    return [(idx2word[i.item()], sims[i].item()) for i in topk_idx]\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_similarity(pairs, desc):\n",
    "    preds, golds = [], []\n",
    "    for w1, w2, sim in tqdm(pairs, desc=f\"ğŸ”¹ {desc}\", ncols=100):\n",
    "        e1, e2 = get_embedding(w1), get_embedding(w2)\n",
    "        if e1 is None or e2 is None:\n",
    "            continue\n",
    "        preds.append(cosine_similarity(e1, e2).cpu().item()) \n",
    "        golds.append(sim)\n",
    "    corr, _ = spearmanr(preds, golds)\n",
    "    oov_ratio = 1 - (len(preds) / len(pairs))\n",
    "    print(f\"  [Info] Evaluated pairs: {len(preds)}/{len(pairs)} (OOV: {oov_ratio:.2%})\")\n",
    "    return corr\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_analogy(analogies, desc):\n",
    "    total, correct = 0, 0\n",
    "    for a, b, c, d_true in tqdm(analogies, desc=f\"ğŸ”¸ {desc}\", ncols=100):\n",
    "        preds = analogy(a, b, c, topk=1)\n",
    "        if not preds:\n",
    "            continue\n",
    "        total += 1\n",
    "        if preds[0][0] == d_true:\n",
    "            correct += 1\n",
    "    return correct / total if total > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986eff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Skip-Gram Negative Sampling (SGNS) ëª¨ë¸ í‰ê°€\n",
    "\n",
    "print(\"=============== ğŸš€ SGNS ëª¨ë¸ í‰ê°€ ì‹œì‘ ===============\")\n",
    "\n",
    "# 1. ëª¨ë¸ ë¡œë“œ\n",
    "try:\n",
    "    ns_model = SkipGram(vocab_size, embedding_dim).to(device)\n",
    "    ns_checkpoint = torch.load(NS_CHECKPOINT_PATH, map_location=device)\n",
    "    ns_model.load_state_dict(ns_checkpoint[\"model_state_dict\"])\n",
    "    ns_model.eval()\n",
    "    print(f\"âœ… NS Checkpoint ë¡œë“œ ì™„ë£Œ: {NS_CHECKPOINT_PATH}\")\n",
    "except NameError:\n",
    "    print(\"âŒ SkipGram í´ë˜ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Cell 1ì˜ importë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "    ns_results = {}\n",
    "except Exception as e:\n",
    "    print(f\"âŒ NS ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    ns_results = {}\n",
    "else:\n",
    "    # 2. ì„ë² ë”© ìºì‹± (V + U í‰ê· )\n",
    "    print(\"\\nâš¡ Caching SGNS embeddings (V + U) / 2...\")\n",
    "    with torch.no_grad():\n",
    "        in_weights = ns_model.in_embeddings.weight.detach().to(device)\n",
    "        \n",
    "        # NS ëª¨ë“œ: Vì™€ Uë¥¼ í‰ê· ë‚´ëŠ” í‘œì¤€ ë°©ì‹ ì‚¬ìš©\n",
    "        if hasattr(ns_model, 'out_embeddings') and ns_model.out_embeddings.weight.size(0) == vocab_size:\n",
    "            out_weights = ns_model.out_embeddings.weight.detach().to(device)\n",
    "            temp_matrix = (in_weights + out_weights) / 2\n",
    "            print(\"ğŸ’¡ In (V)ì™€ Out (U) ì„ë² ë”© í‰ê·  ì‚¬ìš©.\")\n",
    "        else:\n",
    "            temp_matrix = in_weights\n",
    "            print(\"âš ï¸ Out ì„ë² ë”©ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ In (V) ì„ë² ë”©ë§Œ ì‚¬ìš©.\")\n",
    "            \n",
    "        # ì „ì—­ ë³€ìˆ˜ ì—…ë°ì´íŠ¸ ë° float16 ë³€í™˜\n",
    "        global embedding_matrix\n",
    "        embedding_matrix = temp_matrix.half() \n",
    "        \n",
    "    print(f\"âœ… Embedding matrix cached. Size: {embedding_matrix.shape}, Dtype: {embedding_matrix.dtype}\")\n",
    "    \n",
    "    # 3. í‰ê°€ ì‹¤í–‰\n",
    "    ns_results = {}\n",
    "    ns_results[\"WordSim-353\"] = evaluate_similarity(ws_pairs, \"WS-353 (NS)\")\n",
    "    ns_results[\"SimLex-999\"] = evaluate_similarity(simlex_pairs, \"SimLex-999 (NS)\")\n",
    "    ns_results[\"Google Analogy\"] = evaluate_analogy(analogy_pairs, \"Analogy (NS)\")\n",
    "\n",
    "    # 4. ê²°ê³¼ ì¶œë ¥\n",
    "    print(\"\\n\\n====================== SGNS ìµœì¢… ê²°ê³¼ ======================\")\n",
    "    for name, val in ns_results.items():\n",
    "        metric = \"Spearman\" if \"Sim\" in name else \"Accuracy\"\n",
    "        print(f\"ğŸ“Š {name:<15}: {val:.4f} ({metric})\")\n",
    "    print(\"==========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9404ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Skip-Gram Hierarchical Softmax (SGHS) ëª¨ë¸ í‰ê°€\n",
    "\n",
    "print(\"=============== ğŸš€ SGHS ëª¨ë¸ í‰ê°€ ì‹œì‘ ===============\")\n",
    "\n",
    "# 1. ëª¨ë¸ ë¡œë“œ\n",
    "try:\n",
    "    hs_model = SkipGram(vocab_size, embedding_dim).to(device)\n",
    "    hs_checkpoint = torch.load(HS_CHECKPOINT_PATH, map_location=device)\n",
    "    hs_model.load_state_dict(hs_checkpoint[\"model_state_dict\"])\n",
    "    hs_model.eval()\n",
    "    print(f\"âœ… HS Checkpoint ë¡œë“œ ì™„ë£Œ: {HS_CHECKPOINT_PATH}\")\n",
    "except NameError:\n",
    "    print(\"âŒ SkipGram í´ë˜ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Cell 1ì˜ importë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "    hs_results = {}\n",
    "except Exception as e:\n",
    "    print(f\"âŒ HS ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    hs_results = {}\n",
    "else:\n",
    "    # 2. ì„ë² ë”© ìºì‹± (Vë§Œ ì‚¬ìš©)\n",
    "    print(\"\\nâš¡ Caching SGHS embeddings (V only)...\")\n",
    "    with torch.no_grad():\n",
    "        # HS ëª¨ë“œ: V (ì…ë ¥ ì„ë² ë”©)ë§Œ í‰ê°€ì— ì‚¬ìš©í•©ë‹ˆë‹¤. (UëŠ” ë‚´ë¶€ ë…¸ë“œ)\n",
    "        in_weights = hs_model.in_embeddings.weight.detach().to(device)\n",
    "        temp_matrix = in_weights\n",
    "        print(\"ğŸ’¡ In (V) ì„ë² ë”©ë§Œ ì‚¬ìš© (HS í‘œì¤€ ë°©ì‹).\")\n",
    "            \n",
    "        # ì „ì—­ ë³€ìˆ˜ ì—…ë°ì´íŠ¸ ë° float16 ë³€í™˜\n",
    "        global embedding_matrix\n",
    "        embedding_matrix = temp_matrix.half() \n",
    "        \n",
    "    print(f\"âœ… Embedding matrix cached. Size: {embedding_matrix.shape}, Dtype: {embedding_matrix.dtype}\")\n",
    "\n",
    "    # 3. í‰ê°€ ì‹¤í–‰\n",
    "    hs_results = {}\n",
    "    hs_results[\"WordSim-353\"] = evaluate_similarity(ws_pairs, \"WS-353 (HS)\")\n",
    "    hs_results[\"SimLex-999\"] = evaluate_similarity(simlex_pairs, \"SimLex-999 (HS)\")\n",
    "    hs_results[\"Google Analogy\"] = evaluate_analogy(analogy_pairs, \"Analogy (HS)\")\n",
    "    \n",
    "    # 4. ê²°ê³¼ ì¶œë ¥\n",
    "    print(\"\\n\\n====================== SGHS ìµœì¢… ê²°ê³¼ ======================\")\n",
    "    for name, val in hs_results.items():\n",
    "        metric = \"Spearman\" if \"Sim\" in name else \"Accuracy\"\n",
    "        print(f\"ğŸ“Š {name:<15}: {val:.4f} ({metric})\")\n",
    "    print(\"==========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744b6da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: ìµœì¢… ê²°ê³¼ ë¹„êµ\n",
    "\n",
    "print(\"=============== ğŸ† ì „ì²´ ê²°ê³¼ ë¹„êµ ================\")\n",
    "\n",
    "# ns_resultsì™€ hs_resultsê°€ ì •ì˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸\n",
    "if 'ns_results' in locals() and 'hs_results' in locals() and ns_results and hs_results:\n",
    "    results_df = pd.DataFrame({\n",
    "        \"SGNS\": ns_results,\n",
    "        \"SGHS\": hs_results\n",
    "    }).T\n",
    "    \n",
    "    results_df_styled = results_df.style.format(\"{:.4f}\")\n",
    "    display(results_df_styled)\n",
    "else:\n",
    "    print(\"âŒ ëª¨ë“  ëª¨ë¸ì˜ í‰ê°€ ê²°ê³¼ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ì „ ì…€ì˜ ë¡œë“œ ì˜¤ë¥˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35468e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1ì˜ ìƒë‹¨ ê²½ë¡œ ì„¤ì • ë¶€ë¶„ ìˆ˜ì • ì˜ˆì‹œ\n",
    "\n",
    "# NS ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ\n",
    "NS_W5_CHECKPOINT_PATH = \"../weights/sgns_w5_model.pt\"  \n",
    "NS_W10_CHECKPOINT_PATH = \"../weights/sgns_w10_model.pt\"\n",
    "\n",
    "# HS ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ\n",
    "HS_W5_CHECKPOINT_PATH = \"../weights/sghs_w5_model.pt\"\n",
    "HS_W10_CHECKPOINT_PATH = \"../weights/sghs_w10_model.pt\"\n",
    "# ... (ë‚˜ë¨¸ì§€ ì½”ë“œ ë™ì¼)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c059d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: SGNS (Window 10) ëª¨ë¸ í‰ê°€\n",
    "\n",
    "print(\"=============== ğŸš€ SGNS (W=10) ëª¨ë¸ í‰ê°€ ì‹œì‘ ===============\")\n",
    "# ... (NS_W10_CHECKPOINT_PATH ë¡œë“œ) ...\n",
    "\n",
    "# ğŸ’¡ SGNS ì„ë² ë”© ìºì‹± ë¡œì§ (V + U í‰ê· )\n",
    "# ... (ns_model ë¡œë“œ ë° V, U í‰ê·  ê³„ì‚° í›„ embedding_matrix ì—…ë°ì´íŠ¸) ...\n",
    "\n",
    "# í‰ê°€ ì‹¤í–‰\n",
    "ns_w10_results = {}\n",
    "ns_w10_results[\"WordSim-353\"] = evaluate_similarity(ws_pairs, \"WS-353 (NS W=10)\")\n",
    "# ... (SimLex-999, Analogy í‰ê°€) ...\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥ (ns_w10_results)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65df4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: SGHS (Window 5) ëª¨ë¸ í‰ê°€\n",
    "\n",
    "print(\"=============== ğŸš€ SGHS (W=5) ëª¨ë¸ í‰ê°€ ì‹œì‘ ===============\")\n",
    "# ... (HS_W5_CHECKPOINT_PATH ë¡œë“œ) ...\n",
    "\n",
    "# ğŸ’¡ SGHS ì„ë² ë”© ìºì‹± ë¡œì§ (Vë§Œ ì‚¬ìš©)\n",
    "# ... (hs_model ë¡œë“œ ë° Vë§Œ ì‚¬ìš© í›„ embedding_matrix ì—…ë°ì´íŠ¸) ...\n",
    "\n",
    "# í‰ê°€ ì‹¤í–‰\n",
    "hs_w5_results = {}\n",
    "hs_w5_results[\"WordSim-353\"] = evaluate_similarity(ws_pairs, \"WS-353 (HS W=5)\")\n",
    "# ... (SimLex-999, Analogy í‰ê°€) ...\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥ (hs_w5_results)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647d4f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: SGHS (Window 10) ëª¨ë¸ í‰ê°€\n",
    "\n",
    "print(\"=============== ğŸš€ SGHS (W=10) ëª¨ë¸ í‰ê°€ ì‹œì‘ ===============\")\n",
    "# ... (HS_W10_CHECKPOINT_PATH ë¡œë“œ) ...\n",
    "\n",
    "# ğŸ’¡ SGHS ì„ë² ë”© ìºì‹± ë¡œì§ (Vë§Œ ì‚¬ìš©)\n",
    "# ... (hs_model ë¡œë“œ ë° Vë§Œ ì‚¬ìš© í›„ embedding_matrix ì—…ë°ì´íŠ¸) ...\n",
    "\n",
    "# í‰ê°€ ì‹¤í–‰\n",
    "hs_w10_results = {}\n",
    "hs_w10_results[\"WordSim-353\"] = evaluate_similarity(ws_pairs, \"WS-353 (HS W=10)\")\n",
    "# ... (SimLex-999, Analogy í‰ê°€) ...\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥ (hs_w10_results)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f140804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: ìµœì¢… ê²°ê³¼ ë¹„êµ\n",
    "\n",
    "print(\"=============== ğŸ† ì „ì²´ ê²°ê³¼ ë¹„êµ ================\")\n",
    "# ëª¨ë“  ê²°ê³¼ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ í›„ DataFrame ìƒì„±\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"SGNS (W=5)\": ns_w5_results,\n",
    "    \"SGNS (W=10)\": ns_w10_results,\n",
    "    \"SGHS (W=5)\": hs_w5_results,\n",
    "    \"SGHS (W=10)\": hs_w10_results,\n",
    "}).T \n",
    "\n",
    "results_df_styled = results_df.style.format(\"{:.4f}\")\n",
    "display(results_df_styled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "word2vec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
